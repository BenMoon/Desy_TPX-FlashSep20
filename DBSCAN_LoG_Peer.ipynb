{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import h5py\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "import param\n",
    "import yaml\n",
    "from holoviews import opts\n",
    "from scipy.constants import c, physical_constants\n",
    "from tqdm import tqdm\n",
    "\n",
    "hv.extension(\"bokeh\", \"matplotlib\")\n",
    "from bokeh.io import export_png, export_svgs\n",
    "\n",
    "opts.defaults(\n",
    "    opts.Scatter(width=1000, height=300, tools=[\"hover\"]),\n",
    "    opts.Histogram(width=1000, height=300, tools=[\"hover\"]),\n",
    "    opts.Image(width=1000, height=300, tools=[\"hover\"]),\n",
    "    opts.Curve(width=1000, height=300, tools=[\"hover\"]),\n",
    "    opts.Points(width=1000, height=300, tools=[\"hover\"]),\n",
    ")\n",
    "\n",
    "\n",
    "%pylab inline\n",
    "# from matplotlib.colors import LogNorm\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "\n",
    "rcParams[\"figure.figsize\"] = (13.0, 6.0)\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "def get_data_pd(fname: str) -> pd.DataFrame:\n",
    "    try:\n",
    "        with h5py.File(fname, \"r\") as f:\n",
    "            rawNr = f[\"raw/trigger nr\"][:]\n",
    "            rawTof = f[\"raw/tof\"][:] * 1e6\n",
    "            rawTot = f[\"raw/tot\"][:]\n",
    "            rawX = f[\"raw/x\"][:]\n",
    "            rawY = f[\"raw/y\"][:]\n",
    "            centNr = f[\"centroided/trigger nr\"][:]\n",
    "            centTof = f[\"centroided/tof\"][:] * 1e6\n",
    "            centTot = f[\"centroided/tot max\"][:]\n",
    "            centY = f[\"centroided/y\"][:]\n",
    "            centX = f[\"centroided/x\"][:]\n",
    "            size = f[\"centroided/clustersize\"][:]\n",
    "\n",
    "        raw_data = pd.DataFrame(\n",
    "            np.column_stack((rawNr, rawTof, rawTot, rawX, rawY)),\n",
    "            columns=(\"nr\", \"tof\", \"tot\", \"x\", \"y\"),\n",
    "        )\n",
    "        cent_data = pd.DataFrame(\n",
    "            np.column_stack((centNr, centTof, centTot, centX, centY, size)),\n",
    "            columns=(\"nr\", \"tof\", \"tot\", \"x\", \"y\", \"size\"),\n",
    "        )\n",
    "        return raw_data, cent_data\n",
    "    except:\n",
    "        print(f'key \"{keys}\" not known or file \"{fname}\" not existing')\n",
    "\n",
    "\n",
    "def gauss_fwhm(x, *p):\n",
    "    A, mu, fwhm = p\n",
    "    return A * np.exp(-((x - mu) ** 2) / (2.0 * (fwhm ** 2) / (4 * 2 * np.log(2))))\n",
    "\n",
    "\n",
    "def find_peaks_in_microbunch(\n",
    "    data: pd.DataFrame, nr_peaks: int = 4, dt: float = 10, offset: float = 0\n",
    ") -> list:\n",
    "    \"\"\"find first peak in micro-bunch\"\"\"\n",
    "    peaks = []\n",
    "    for i in range(nr_peaks):\n",
    "        mask = np.logical_and(\n",
    "            data[\"tof\"] > (offset + i * dt), data[\"tof\"] < (offset + i * dt + 1)\n",
    "        )\n",
    "        x_hist, x_edges = np.histogram(data[\"tof\"][mask], bins=1_000)\n",
    "        x = (x_edges[:-1] + x_edges[1:]) * 0.5\n",
    "        popt, pcov = curve_fit(\n",
    "            gauss_fwhm, x, x_hist, p0=[x_hist.max(), x[x_hist.argmax()], 0.05]\n",
    "        )\n",
    "        peaks.append(popt[1])\n",
    "    return peaks\n",
    "\n",
    "\n",
    "def shift_microbunch_pulses(\n",
    "    data: pd.DataFrame, nr_peaks: int = 4, dt: float = 10, offset: float = 0\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Fold consecutive micro-bunch pulses back to first\"\"\"\n",
    "    peaks = find_peaks_in_microbunch(data, nr_peaks, dt, offset)\n",
    "\n",
    "    # shift bunches\n",
    "    for i in range(1, nr_peaks):\n",
    "        mask = np.logical_and(\n",
    "            data[\"tof\"] >= offset + i * dt, data[\"tof\"] < offset + (i + 1) * dt\n",
    "        )\n",
    "        data[\"tof\"][mask] -= peaks[i] - peaks[0]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def radial_profile(data: np.array, center: tuple) -> np.array:\n",
    "    y, x = np.indices(data.shape)\n",
    "    r = np.sqrt((x - center[0]) ** 2 + (y - center[1]) ** 2)\n",
    "    r = r.astype(np.int)\n",
    "\n",
    "    tbin = np.bincount(r.ravel(), data.ravel())\n",
    "    nr = np.bincount(r.ravel())\n",
    "    radialprofile = tbin / nr\n",
    "    return radialprofile\n",
    "\n",
    "\n",
    "get_x_axis_from_bins = lambda x_bins: 0.5 * (x_bins[1:] + x_bins[:-1])\n",
    "file_title = lambda x: os.path.basename(x).rstrip(\".hdf5\")\n",
    "\n",
    "with open(\"runs.yaml\") as f:\n",
    "    runNrs = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts.defaults(\n",
    "    opts.Image(frame_width=400, frame_height=400, colorbar=True, cmap=\"jet\", logz=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define constants and conversion functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# physical constants\n",
    "u = physical_constants[\"atomic mass constant\"][0]\n",
    "J2eV = 1 / physical_constants[\"electron volt-joule relationship\"][0]\n",
    "e = physical_constants[\"elementary charge\"][0]  # C\n",
    "u = physical_constants[\"atomic mass constant\"][0]\n",
    "E = 269.5 * 100  # 158.9 * 100  # V/m, from Benjamins Simion simulation\n",
    "m = 14.0067 * u  # kg\n",
    "\n",
    "##########\n",
    "# constants from experiment\n",
    "x_cent, y_cent, detector_radius = 136, 140, 112\n",
    "tof_center = 2.4213223243819346  # extracted from same variable in CH3I_TOFs.ipynb\n",
    "# https://www.wolframalpha.com/input/?i=26.5713+mm%2F%2810+mm%2Fus+*+2.2567+us%29 from Benjamin Email\n",
    "vmi_magnification = 28.6445 / (10 * 2.4275)\n",
    "c_pixel = (\n",
    "    78 / (2 * detector_radius) * 1e-3\n",
    ")  # 78mm / (224 pixel) conversion von pixel nach m\n",
    "# https://confluence.desy.de/display/TPX3BT/2020/12/17/VMI+calibration+with+Simion\n",
    "tof_offset = 0.926  # arrival time of photon peak\n",
    "\n",
    "# functions for conversion\n",
    "r_to_vel = lambda r, tof: (r * c_pixel / vmi_magnification / (tof * 1e-6))  # for m/s\n",
    "velocity_to_eV = lambda v: 0.5 * v ** 2 * 14.0067 * u * J2eV\n",
    "pixel_to_velocity = lambda pixel, tof_center: velocity_to_eV(\n",
    "    r_to_vel(pixel, tof_center)\n",
    ")\n",
    "\n",
    "\n",
    "def convert_velocity(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"convert absolute coordinate from VMI to relative coordinate and\n",
    "    calculate velocities\n",
    "    \"\"\"\n",
    "    df[\"tof\"] -= tof_offset - 0.13\n",
    "    df[\"x_rel\"] = df[\"x\"] - x_cent\n",
    "    df[\"y_rel\"] = df[\"y\"] - y_cent\n",
    "    df[\"r\"] = np.sqrt(df[\"x_rel\"] ** 2 + df[\"y_rel\"] ** 2)\n",
    "    df[\"theta\"] = np.arctan2(\n",
    "        df[\"y_rel\"], df[\"x_rel\"]\n",
    "    )  # alternatively: np.arctan2(df['y'], df['r'])\n",
    "\n",
    "    df[\"v_x\"] = df[\"x_rel\"] * c_pixel / vmi_magnification / (df[\"tof\"] * 1e-6)  # m/s\n",
    "    df[\"v_y\"] = df[\"y_rel\"] * c_pixel / vmi_magnification / (df[\"tof\"] * 1e-6)  # m/s\n",
    "    df[\"xy_velocity\"] = r_to_vel(df[\"r\"], df[\"tof\"])\n",
    "\n",
    "    # conversion only correct for m/q=14 peak, for other peak tof_center needs to be changed\n",
    "    # convert velocity to energy; E = 0.5 v^2 m\n",
    "    df[\"eV\"] = velocity_to_eV(df[\"xy_velocity\"])\n",
    "\n",
    "    Δt = (df[\"tof\"] - tof_center) * 1e-6  # convert to s\n",
    "    df[\"v_z\"] = Δt * e * E / m\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from standard clustering\n",
    "file_dbscan = \"out/ion-run_0016_20200903-2202.hdf5\"\n",
    "name = os.path.basename(file_dbscan).rstrip(\".hdf5\")\n",
    "data_dbscan = convert_velocity(get_data_pd(file_dbscan)[1])\n",
    "data_raw = convert_velocity(get_data_pd(file_dbscan)[0])\n",
    "\n",
    "# load data from LoG\n",
    "file_log_tobi = \"out/ion-run_0016_20200903-2202_LoG-Tobi.npy\"\n",
    "data_log_tobi = convert_velocity(\n",
    "    pd.DataFrame(np.load(file_log_tobi), columns=(\"nr\", \"x\", \"y\", \"tof\", \"tot\"))\n",
    ")\n",
    "file_log_old = \"out/ion-run_0016_20200903-2202_LoG-rawConv.npy\"\n",
    "data_log_old = convert_velocity(\n",
    "    pd.DataFrame(np.load(file_log_old), columns=(\"nr\", \"x\", \"y\", \"tof\", \"tot\"))\n",
    ")\n",
    "\n",
    "# load data from Peer\n",
    "file_peer = \"out/ion-run_0016_20200903-2202_peer.npy\"\n",
    "data_peer = convert_velocity(\n",
    "    pd.DataFrame(np.load(file_peer), columns=(\"nr\", \"x\", \"y\", \"tof\", \"tot\"))\n",
    ")\n",
    "\n",
    "####\n",
    "# whole pulse train\n",
    "# DBSCAN\n",
    "df = shift_microbunch_pulses(\n",
    "    get_data_pd(file_dbscan)[1],\n",
    "    nr_peaks=runNrs[name][\"pulses\"],\n",
    "    dt=1 / runNrs[name][\"rep\"] * 1e3,\n",
    "    offset=0.9,\n",
    ")\n",
    "data_dbscan_all = convert_velocity(df)\n",
    "\n",
    "# raw data all\n",
    "df = shift_microbunch_pulses(\n",
    "    get_data_pd(file_dbscan)[0],\n",
    "    nr_peaks=runNrs[name][\"pulses\"],\n",
    "    dt=1 / runNrs[name][\"rep\"] * 1e3,\n",
    "    offset=0.9,\n",
    ")\n",
    "data_raw_all = convert_velocity(df)\n",
    "\n",
    "# LoG Tobi\n",
    "df = shift_microbunch_pulses(\n",
    "    pd.DataFrame(np.load(file_log_tobi), columns=(\"nr\", \"x\", \"y\", \"tof\", \"tot\")),\n",
    "    nr_peaks=runNrs[name][\"pulses\"],\n",
    "    dt=1 / runNrs[name][\"rep\"] * 1e3,\n",
    "    offset=0.9,\n",
    ")\n",
    "data_log_tobi_all = convert_velocity(df)\n",
    "\n",
    "# LoG Old\n",
    "df = shift_microbunch_pulses(\n",
    "    pd.DataFrame(np.load(file_log_old), columns=(\"nr\", \"x\", \"y\", \"tof\", \"tot\")),\n",
    "    nr_peaks=runNrs[name][\"pulses\"],\n",
    "    dt=1 / runNrs[name][\"rep\"] * 1e3,\n",
    "    offset=0.9,\n",
    ")\n",
    "data_log_old_all = convert_velocity(df)\n",
    "\n",
    "\n",
    "# load data from Peer\n",
    "df = shift_microbunch_pulses(\n",
    "    pd.DataFrame(np.load(file_peer), columns=(\"nr\", \"x\", \"y\", \"tof\", \"tot\")),\n",
    "    nr_peaks=runNrs[name][\"pulses\"],\n",
    "    dt=1 / runNrs[name][\"rep\"] * 1e3,\n",
    "    offset=0.9,\n",
    ")\n",
    "data_peer_all = convert_velocity(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### analyse data: TOFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TOF_spectrum(data, title=\"DBSCAN\", bins=15_000, alpha=1):\n",
    "    x_hist, x_bins = np.histogram(data[\"tof\"], bins=bins)\n",
    "    tof = hv.Histogram((x_hist, x_bins), label=title).opts(\n",
    "        xlabel=\"TOF (µs)\", title=title\n",
    "    )\n",
    "    return tof.opts(alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tof_dbscan = TOF_spectrum(data_dbscan.query(\"tof < 40\"), title=\"DBSCAN\", alpha=0.7)\n",
    "tof_log_tobi = TOF_spectrum(\n",
    "    data_log_tobi.query(\"tof < 40\"), title=\"DBSCAN LoG Tobi\", alpha=0.5\n",
    ")\n",
    "tof_log_old = TOF_spectrum(\n",
    "    data_log_old.query(\"tof < 40\"), title=\"DBSCAN LoG Old\", alpha=0.4\n",
    ")\n",
    "tof_peer = TOF_spectrum(data_peer.query(\"tof < 40\"), title=\"Peer\", alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tof_dbscan + tof_log_old + tof_log_tobi + tof_peer).cols(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tof_raw_all = TOF_spectrum(data_raw_all.query(\"tof < 5\"), title=\"raw\", bins=2_000)\n",
    "tof_dbscan_all = TOF_spectrum(\n",
    "    data_dbscan_all.query(\"tof < 5\"), title=\"DBSCAN\", bins=2_000, alpha=0.7\n",
    ")\n",
    "tof_log_tobi_all = TOF_spectrum(\n",
    "    data_log_tobi_all.query(\"tof < 5\"), title=\"DBSCAN LoG Tobi\", bins=2_000, alpha=0.5\n",
    ")\n",
    "tof_log_old_all = TOF_spectrum(\n",
    "    data_log_old_all.query(\"tof < 5\"), title=\"DBSCAN LoG Old\", bins=2_000, alpha=0.5\n",
    ")\n",
    "tof_peer_all = TOF_spectrum(data_peer_all.query(\"tof < 5\"), title=\"Peer\", bins=2_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tof_raw_all * tof_dbscan_all + tof_log_old_all + tof_log_tobi_all + tof_peer_all).cols(\n",
    "    1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tof_peer * tof_dbscan * tof_log_tobi * tof_log_old).opts(\n",
    "    title=\"m/q=14, 1st pulse\", xlim=(2.31, 2.55), ylim=(0, 10_000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tof_peer_all * tof_dbscan_all * tof_log_tobi_all * tof_log_old_all).opts(\n",
    "    title=\"m/q=14, whole pulse train\", xlim=(2.31, 2.55), ylim=(0, 80_000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tof_peer * tof_dbscan * tof_log_tobi * tof_log_old).opts(\n",
    "    title=\"parent ion, 1st pulse\", xlim=(3.34, 3.4), ylim=(0, 15_000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tof_peer_all * tof_dbscan_all * tof_log_tobi_all * tof_log_old_all).opts(\n",
    "    title=\"parent ion, 1st pulse\", xlim=(3.34, 3.5), ylim=(0, 80_000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_velo_distrib(df: pd.DataFrame, title: str) -> hv.Histogram:\n",
    "    bins = np.linspace(-15_000, 15_000, 100)\n",
    "\n",
    "    x_hist, x_bins = np.histogram(df[\"v_x\"], bins=bins)\n",
    "    hist_vx = hv.Histogram((x_hist, x_bins), label=\"v_x\").opts(\n",
    "        clim=(0.1, None), title=title, xlabel=\"velocity (m/s)\"\n",
    "    )\n",
    "    x_hist, x_bins = np.histogram(df[\"v_y\"], bins=bins)\n",
    "    hist_vy = hv.Histogram((x_hist, x_bins), label=\"v_y\").opts(\n",
    "        clim=(0.1, None),\n",
    "    )\n",
    "    x_hist, x_edges = np.histogram(df[\"v_z\"], bins=bins)\n",
    "    hist_vz = hv.Histogram((x_hist, x_edges), label=\"v_z\").opts(xlabel=\"v_z (m/s)\")\n",
    "    # hist_vz\n",
    "    return (hist_vx * hist_vy.opts(alpha=0.5) * hist_vz.opts(alpha=0.3)).opts(\n",
    "        xlabel=\"velocity (m/s)\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_velo_distrib(\n",
    "    data_dbscan.query(\"tof>2.35 & tof<2.55\"),\n",
    "    title=\"Velocity distribution DBSCAN, 1st pulse\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_velo_distrib(\n",
    "    data_dbscan_all.query(\"tof>2.35 & tof<2.55\"),\n",
    "    title=\"Velocity distribution DBSCAN, whole train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_velo_distrib(\n",
    "    data_log_old.query(\"tof>2.35 & tof<2.55\"),\n",
    "    title=\"Velocity distribution LoG - old, 1st pulse\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_velo_distrib(\n",
    "    data_log_old_all.query(\"tof>2.35 & tof<2.55\"),\n",
    "    title=\"Velocity distribution LoG - old, whole train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_velo_distrib(\n",
    "    data_log_tobi.query(\"tof>2.35 & tof<2.55\"),\n",
    "    title=\"Velocity distribution LoG - Tobi, 1st pulse\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_velo_distrib(\n",
    "    data_log_tobi_all.query(\"tof>2.35 & tof<2.55\"),\n",
    "    title=\"Velocity distribution LoG - Tobi, whole train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_velo_distrib(\n",
    "    data_peer.query(\"tof>2.35 & tof<2.55\"),\n",
    "    title=\"Velocity distribution Peer, 1st pulse\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_velo_distrib(\n",
    "    data_peer_all.query(\"tof>2.35 & tof<2.55\"),\n",
    "    title=\"Velocity distribution Peer, whole train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D VMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "\n",
    "def hist2D_vmi(\n",
    "    df: pd.DataFrame,\n",
    "    p: dict,\n",
    "    bins=(range(256), range(256)),\n",
    "    sigma: int = None,\n",
    "    weights: str = None,\n",
    ") -> hv.Image:\n",
    "    weights_data = df[weights] if weights is not None else None\n",
    "    xy_hist, x_bins, y_bins = np.histogram2d(\n",
    "        df[p[\"x\"]], df[p[\"y\"]], bins=bins, weights=weights_data\n",
    "    )\n",
    "    if sigma is not None:\n",
    "        image = gaussian_filter(xy_hist.T[::-1], sigma=sigma)\n",
    "    else:\n",
    "        image = xy_hist.T[::-1]\n",
    "    hist2d = hv.Image(\n",
    "        image, bounds=(x_bins[0], y_bins[0], x_bins[-1], y_bins[-1])\n",
    "    ).opts(\n",
    "        axiswise=True,\n",
    "        logz=True,\n",
    "        clim=(0.1, None),\n",
    "        title=p[\"title\"],\n",
    "        xlabel=p[\"xlabel\"],\n",
    "        ylabel=p[\"ylabel\"],\n",
    "    )\n",
    "\n",
    "    return hist2d  # _slice_1st + hist2d_slice_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Δv_z = 1_000\n",
    "param1 = {\n",
    "    \"title\": f\"VMI DBSCAN for {-1*Δv_z}<v_z<{Δv_z} m/s, 1st pulse\",\n",
    "    \"x\": \"x\",\n",
    "    \"y\": \"y\",\n",
    "    \"xlabel\": \"pixel\",\n",
    "    \"ylabel\": \"pixel\",\n",
    "}\n",
    "df1 = data_dbscan.query(f\"tof>2.35 & tof<2.55 & v_z>{-1*Δv_z} & v_z<{Δv_z}\")\n",
    "df2 = data_dbscan_all.query(f\"tof>2.35 & tof<2.55 & v_z>{-1*Δv_z} & v_z<{Δv_z}\")\n",
    "param2 = param1.copy()\n",
    "param2[\"title\"] = f\"VMI DBSCAN for {-1*Δv_z}<v_z<{Δv_z} m/s, whole pulse train\"\n",
    "bins = (range(256), range(256))\n",
    "hist2D_vmi(df1, param1, bins) + hist2D_vmi(df2, param2, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Δv_y = 1000\n",
    "\n",
    "df1 = data_dbscan.query(f\"tof>2.35 & tof<2.55 & v_y>{-1*Δv_y} & v_y<{Δv_y}\")\n",
    "param1 = {\n",
    "    \"title\": f\"VMI DBSCAN for {-1*Δv_z}<v_z<{Δv_z} m/s, 1st pulse\",\n",
    "    \"x\": \"v_x\",\n",
    "    \"y\": \"v_z\",\n",
    "    \"xlabel\": \"v_x (m/s)\",\n",
    "    \"ylabel\": \"v_z (m/s)\",\n",
    "}\n",
    "df2 = data_dbscan_all.query(f\"tof>2.35 & tof<2.55 & v_y>{-1*Δv_y} & v_y<{Δv_y}\")\n",
    "param2 = param1.copy()\n",
    "param2[\"title\"] = f\"VMI DBSCAN for {-1*Δv_y}<v_z<{Δv_y} m/s, whole pulse train\"\n",
    "bins = np.linspace(-12_000, 12_000, 200)\n",
    "hist2D_vmi(df1, param1, bins=bins) + hist2D_vmi(df2, param2, bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Δv_z = 1000\n",
    "\n",
    "df1 = data_log_tobi.query(f\"tof>2.35 & tof<2.55 & v_z>{-1*Δv_z} & v_z<{Δv_z}\")\n",
    "param1 = {\n",
    "    \"title\": f\"LoG Tobi for {-1*Δv_z}<v_z<{Δv_z} m/s, 1st pulse\",\n",
    "    \"x\": \"x\",\n",
    "    \"y\": \"y\",\n",
    "    \"xlabel\": \"pixel\",\n",
    "    \"ylabel\": \"pixel\",\n",
    "}\n",
    "df2 = data_log_tobi_all.query(f\"tof>2.35 & tof<2.55 & v_z>{-1*Δv_z} & v_z<{Δv_z}\")\n",
    "param2 = param1.copy()\n",
    "param2[\"title\"] = f\"LoG Tobi for {-1*Δv_z}<v_z<{Δv_z} m/s, whole pulse train\"\n",
    "bins = (range(256), range(256))\n",
    "hist2D_vmi(df1, param1, bins=bins) + hist2D_vmi(df2, param2, bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Δv_y = 1000\n",
    "\n",
    "df1 = data_log_tobi.query(f\"tof>2.35 & tof<2.55 & v_y>{-1*Δv_y} & v_y<{Δv_y}\")\n",
    "param1 = {\n",
    "    \"title\": f\"LoG Tobi for {-1*Δv_z}<v_z<{Δv_z} m/s, 1st pulse\",\n",
    "    \"x\": \"v_x\",\n",
    "    \"y\": \"v_z\",\n",
    "    \"xlabel\": \"v_x (m/s)\",\n",
    "    \"ylabel\": \"v_z (m/s)\",\n",
    "}\n",
    "df2 = data_log_tobi_all.query(f\"tof>2.35 & tof<2.55 & v_y>{-1*Δv_y} & v_y<{Δv_y}\")\n",
    "param2 = param1.copy()\n",
    "param2[\"title\"] = f\"LoG Tobi for {-1*Δv_y}<v_z<{Δv_y} m/s, whole pulse train\"\n",
    "bins = np.linspace(-12_000, 12_000, 200)\n",
    "hist2D_vmi(df1, param1, bins=bins) + hist2D_vmi(df2, param2, bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Δv_x = 1000\n",
    "vx_slice = df2.query(f\"v_x>{-1*Δv_x} & v_x<{Δv_x}\")\n",
    "x_hist, x_bins = np.histogram(vx_slice[\"v_z\"], bins=(np.linspace(-12_000, 12_000, 200)))\n",
    "hv.Histogram((x_hist, x_bins)).opts(xlabel=\"v_z (m/s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Δv_y = 1000\n",
    "\n",
    "df1 = data_log_old.query(f\"tof>2.35 & tof<2.55 & v_y>{-1*Δv_y} & v_y<{Δv_y}\")\n",
    "param1 = {\n",
    "    \"title\": f\"LoG Old for {-1*Δv_z}<v_z<{Δv_z} m/s, 1st pulse\",\n",
    "    \"x\": \"v_x\",\n",
    "    \"y\": \"v_z\",\n",
    "    \"xlabel\": \"v_x (m/s)\",\n",
    "    \"ylabel\": \"v_z (m/s)\",\n",
    "}\n",
    "df2 = data_log_old_all.query(f\"tof>2.35 & tof<2.55 & v_y>{-1*Δv_y} & v_y<{Δv_y}\")\n",
    "param2 = param1.copy()\n",
    "param2[\"title\"] = f\"LoG Old for {-1*Δv_y}<v_z<{Δv_y} m/s, whole pulse train\"\n",
    "bins = np.linspace(-12_000, 12_000, 200)\n",
    "hist2D_vmi(df1, param1, bins=bins) + hist2D_vmi(df2, param2, bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df2 = data_log_old_all.query(f\"tof>2.35 & tof<2.55 & v_y>{-1*Δv_y} & v_y<{Δv_y}\")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "plt.hist2d(\n",
    "    df2[\"v_x\"],\n",
    "    df2[\"v_z\"],\n",
    "    bins=np.linspace(-12_000, 12_000, 200),\n",
    "    norm=mpl.colors.LogNorm(),\n",
    "    cmap=plt.cm.jet,\n",
    ")\n",
    "# square plot\n",
    "ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Δv_x = 1000\n",
    "vx_slice = df2.query(f\"v_x>{-1*Δv_x} & v_x<{Δv_x}\")\n",
    "x_hist, x_bins = np.histogram(vx_slice[\"v_z\"], bins=(np.linspace(-12_000, 12_000, 200)))\n",
    "hv.Histogram((x_hist, x_bins)).opts(xlabel=\"v_z (m/s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Δv_y = 1000\n",
    "\n",
    "df1 = data_peer.query(f\"tof>2.35 & tof<2.55 & v_y>{-1*Δv_y} & v_y<{Δv_y}\")\n",
    "param1 = {\n",
    "    \"title\": f\"Peer for {-1*Δv_y}<v_y<{Δv_y} m/s, 1st pulse\",\n",
    "    \"x\": \"v_x\",\n",
    "    \"y\": \"v_z\",\n",
    "    \"xlabel\": \"v_x (m/s)\",\n",
    "    \"ylabel\": \"v_z (m/s)\",\n",
    "}\n",
    "df2 = data_peer_all.query(f\"tof>2.35 & tof<2.55 & v_y>{-1*Δv_y} & v_y<{Δv_y}\")\n",
    "param2 = param1.copy()\n",
    "param2[\"title\"] = f\"Peer for {-1*Δv_y}<v_y<{Δv_y} m/s, whole pulse train\"\n",
    "bins = np.linspace(-12_000, 12_000, 200)\n",
    "hist2D_vmi(df1, param1, bins=bins) + hist2D_vmi(df2, param2, bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot TOF as TOT to see if pixels from previous event are still \"blind\"\n",
    "Δv_y = 1000\n",
    "\n",
    "df1 = data_peer_all.query(f\"tof>1 & tof<2.7 & v_y>{-1*Δv_y} & v_y<{Δv_y}\")\n",
    "param1 = {\n",
    "    \"title\": f\"Peer for {-1*Δv_y}<v_y<{Δv_y} m/s\",\n",
    "    \"x\": \"tot\",\n",
    "    \"y\": \"tof\",\n",
    "    \"xlabel\": \"TOT\",\n",
    "    \"ylabel\": \"TOF\",\n",
    "}\n",
    "bins = (np.arange(0, 3000, 25), np.linspace(1, 2.7, 200))\n",
    "hist2D_vmi(df1, param1, bins=bins) + hist2D_vmi(\n",
    "    df1, param1, bins=(np.arange(0, 3000, 25), np.linspace(2.2, 2.7, 200))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial distribution of peak at 1.8µs\n",
    "df1 = data_peer_all.query(f\"tof>1.6 & tof<2 & v_y>{-1*Δv_y} & v_y<{Δv_y}\")\n",
    "df2 = data_peer_all.query(f\"tof>2.3 & tof<2.5 & v_y>{-1*Δv_y} & v_y<{Δv_y}\")\n",
    "param1 = {\n",
    "    \"title\": f\"Spatial distribution proton peak for {-1*Δv_y}<v_y<{Δv_y} m/s\",\n",
    "    \"x\": \"x\",\n",
    "    \"y\": \"y\",\n",
    "    \"xlabel\": \"x (pixel)\",\n",
    "    \"ylabel\": \"y (pixel)\",\n",
    "}\n",
    "param2 = param1.copy()\n",
    "param2[\"title\"] = f\"Spatial distribution N₂ peak for {-1*Δv_y}<v_y<{Δv_y} m/s\"\n",
    "bins = range(256)\n",
    "hist2D_vmi(df1, param1, bins=bins) + hist2D_vmi(df2, param2, bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot TOF as TOT to see if pixels from previous event are still \"blind\"\n",
    "Δv_y = 1000\n",
    "\n",
    "df1 = data_raw_all.query(f\"tof>1 & tof<2.7 & v_y>{-1*Δv_y} & v_y<{Δv_y}\")\n",
    "\n",
    "param1 = {\n",
    "    \"title\": f\"Raw for {-1*Δv_y}<v_y<{Δv_y} m/s\",\n",
    "    \"x\": \"tot\",\n",
    "    \"y\": \"tof\",\n",
    "    \"xlabel\": \"TOT\",\n",
    "    \"ylabel\": \"TOF\",\n",
    "}\n",
    "df2 = data_peer_all.query(f\"tof>2.2 & tof<2.7 & v_y>{-1*Δv_y} & v_y<{Δv_y}\")\n",
    "param2 = param1.copy()\n",
    "param2[\"title\"] = f\"Peer for {-1*Δv_y}<v_y<{Δv_y} m/s\"\n",
    "bins = (np.arange(0, 3000, 25), np.linspace(2.2, 2.7, 200))\n",
    "hist2D_vmi(df1, param1, bins=bins) + hist2D_vmi(df2, param2, bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial distribution of peak at 1.8µs\n",
    "df1 = data_raw_all.query(f\"tof>1.6 & tof<2 & v_y>{-1*Δv_y} & v_y<{Δv_y}\")\n",
    "df2 = data_raw_all.query(f\"tof>2.3 & tof<2.5 & v_y>{-1*Δv_y} & v_y<{Δv_y}\")\n",
    "param1 = {\n",
    "    \"title\": f\"Raw spatial distribution proton peak for {-1*Δv_y}<v_y<{Δv_y} m/s\",\n",
    "    \"x\": \"x\",\n",
    "    \"y\": \"y\",\n",
    "    \"xlabel\": \"x (pixel)\",\n",
    "    \"ylabel\": \"y (pixel)\",\n",
    "}\n",
    "param2 = param1.copy()\n",
    "param2[\"title\"] = f\"Raw Spatial distribution N₂ peak for {-1*Δv_y}<v_y<{Δv_y} m/s\"\n",
    "bins = range(256)\n",
    "hist2D_vmi(df1, param1, bins=bins) + hist2D_vmi(df2, param2, bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Δv_x = 1000\n",
    "vx_slice = df2.query(f\"v_x>{-1*Δv_x} & v_x<{Δv_x}\")\n",
    "x_hist, x_bins = np.histogram(vx_slice[\"v_z\"], bins=(np.linspace(-12_000, 12_000, 200)))\n",
    "hv.Histogram((x_hist, x_bins)).opts(xlabel=\"v_z (m/s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope1 = (2.49 - 2.38) / 150 * 1e3\n",
    "slope2 = (2.47 - 2.35) / 150 * 1e3\n",
    "print(f\"slope {slope1:.3f} ns/pixel, {slope1*256:.1f} ns over sensor\")\n",
    "print(f\"slope {slope2:.3f} ns/pixel, {slope2*256:.1f} ns over sensor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Δv_y = 1000\n",
    "\n",
    "df2 = data_peer_all.query(f\"tof>2.35 & tof<2.55\")\n",
    "p2 = {\n",
    "    \"title\": f\"Peer whole pulse train\",\n",
    "    \"x\": \"x\",\n",
    "    \"y\": \"tof\",\n",
    "    \"xlabel\": \"x (pixel)\",\n",
    "    \"ylabel\": \"TOF (µs)\",\n",
    "}\n",
    "bins = (range(256), np.linspace(2.34, 2.51, 256))\n",
    "\n",
    "# whole pulse train\n",
    "xy_hist, x_bins, y_bins = np.histogram2d(\n",
    "    df2[\"x\"],\n",
    "    df2[\"tof\"],\n",
    "    bins=bins,\n",
    ")\n",
    "\n",
    "hist2d_slice_all = hist2D_vmi(df2, p2, bins=bins)\n",
    "a = hv.Curve(((100, 200), (2.42, 2.49)))\n",
    "b = hv.Curve(((100, 172), (2.352, 2.36)))\n",
    "\n",
    "slope3 = ((2.381 - 2.374) / (172 - 100)) * 1e3\n",
    "slope4 = ((2.361 - 2.355) / (172 - 100)) * 1e3\n",
    "c = hv.Curve(((100, 172), (2.374, 2.381)), label=f\"{slope3*256:.1f} ns over sensor\")\n",
    "d = hv.Curve(((100, 172), (2.355, 2.361)), label=f\"{slope4*256:.1f} ns over sensor\")\n",
    "hv.Layout((hist2d_slice_all * a * b) + hist2D_vmi(df2, p2, bins=bins, sigma=1) * c * d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"slope {slope3:.3f} ns/pixel, {slope3*256:.1f} ns over sensor\")\n",
    "print(f\"slope {slope4:.3f} ns/pixel, {slope4*256:.1f} ns over sensor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = xy_hist.T[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed = gaussian_filter(Z, sigma=0.7)\n",
    "bounds = (x_bins[0], y_bins[0], x_bins[-1], y_bins[-1])\n",
    "hv.Image(smoothed, bounds=bounds).opts(title=\"Gauss filter (2D)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axe = get_x_axis_from_bins(y_bins)\n",
    "a = [hv.Curve((x_axe, Z[:, i])) for i in range(130, 140)]\n",
    "b = [hv.Curve((x_axe, smoothed[:, i])) for i in range(130, 140)]\n",
    "hv.Layout(\n",
    "    hv.Overlay(a).opts(title=\"raw data\", xlabel=\"TOF (µs)\")\n",
    "    + hv.Overlay(b).opts(title=\"Gauss smoothed data\", xlabel=\"TOF (µs)\")\n",
    ").cols(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Curve((x_axe, savgol_filter(Z[:, 135], 9, 3))).opts(\n",
    "    title=\"Savgol smoothed\"\n",
    ") * hv.Curve((x_axe, xy_hist.T[::-1][:, 135]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_savgol = [\n",
    "    hv.Curve((x_axe, savgol_filter(Z[:, i], 9, 3))) for i in range(130, 140)\n",
    "]\n",
    "hv.Overlay(smoothed_savgol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = [savgol_filter(Z[:, i], 9, 3) for i in range(255)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Image(\n",
    "    np.asarray(new_image).T, bounds=(x_bins[0], y_bins[0], x_bins[-1], y_bins[-1])\n",
    ").opts(frame_width=400, frame_height=400, title=\"savgol_filter (1D)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "Z_normed = Z / Z.max()\n",
    "Z_normed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-100, 100, 255)  # x_axe\n",
    "splined = [UnivariateSpline(x, Z_normed[:, i], s=0.2) for i in range(0, 255)]\n",
    "a = [hv.Curve((x_axe, i(x))) for i in splined[130:140]]\n",
    "hv.Overlay(a).opts(xlabel=\"TOF (µs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curves_2nd_grad = [i.derivative(n=2)(x) for i in splined]\n",
    "a = [hv.Curve((x_axe, i)) for i in curves_2nd_grad[130:140]]\n",
    "hv.Overlay(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_2nd_grad = np.column_stack(curves_2nd_grad)\n",
    "hv.Image(image_2nd_grad, bounds=bounds).opts(xlim=(120, 150), ylim=(2.35, 2.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nitrogen, raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOF_spectrum(data_raw.query(\"tof < 40\"), title=\"raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Δv_y = 1000\n",
    "\n",
    "p1 = {\n",
    "    \"title\": f\"Raw whole pulse train\",\n",
    "    \"x\": \"x\",\n",
    "    \"y\": \"tof\",\n",
    "    \"xlabel\": \"x (pixel)\",\n",
    "    \"ylabel\": \"TOF (µs)\",\n",
    "}\n",
    "p2 = p1.copy()\n",
    "p2[\"x\"] = \"y\"\n",
    "p2[\"xlabel\"] = \"y (pixel)\"\n",
    "\n",
    "df2 = data_raw_all.query(f\"tof>2.33 & tof<2.55\")\n",
    "bins = (range(256), np.linspace(2.33, 2.55, 500))\n",
    "\n",
    "hist2d_slice_all = hist2D_vmi(df2, p2, bins=bins)\n",
    "\n",
    "x, y = [100, 172], [2.368, 2.374]\n",
    "slope3 = ((y[1] - y[0]) / (x[1] - x[0])) * 1e3\n",
    "c = hv.Curve((x, y), label=f\"{slope3*256:.1f} ns over sensor\")\n",
    "x, y = [100, 172], [2.346, 2.352]\n",
    "slope4 = ((y[1] - y[0]) / (x[1] - x[0])) * 1e3\n",
    "d = hv.Curve((x, y), label=f\"{slope4*256:.1f} ns / sensor\")\n",
    "hv.Layout(\n",
    "    hist2D_vmi(df2, p1, bins=bins, sigma=1) * c * d\n",
    "    + hist2D_vmi(df2, p2, bins=bins, sigma=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data_raw_all.query(f\"tof>2.35 & tof<2.55 & v_y>{-1*Δv_y} & v_y<{Δv_y}\")\n",
    "p1 = {\n",
    "    \"title\": f\"Raw for {-1*Δv_y}<v_y<{Δv_y} m/s, whole pulse train\",\n",
    "    \"x\": \"x\",\n",
    "    \"y\": \"tof\",\n",
    "    \"xlabel\": \"x (pixel)\",\n",
    "    \"ylabel\": \"TOF (µs)\",\n",
    "}\n",
    "Δv_x = 1000\n",
    "df2 = data_raw_all.query(f\"tof>2.35 & tof<2.55 & v_x>{-1*Δv_x} & v_x<{Δv_x}\")\n",
    "p2 = {\n",
    "    \"title\": f\"Raw for {-1*Δv_x}<v_x<{Δv_x} m/s, whole pulse train\",\n",
    "    \"x\": \"y\",\n",
    "    \"y\": \"tof\",\n",
    "    \"xlabel\": \"y (pixel)\",\n",
    "    \"ylabel\": \"TOF (µs)\",\n",
    "}\n",
    "df3 = data_raw_all.query(f\"tof>2.35 & tof<2.55\")\n",
    "p3 = {\n",
    "    \"title\": f\"Raw\",\n",
    "    \"x\": \"tot\",\n",
    "    \"y\": \"tof\",\n",
    "    \"xlabel\": \"TOT (ns)\",\n",
    "    \"ylabel\": \"TOF (µs)\",\n",
    "}\n",
    "df4 = data_peer_all.query(f\"tof>2.35 & tof<2.55\")\n",
    "p4 = {\n",
    "    \"title\": f\"Peer\",\n",
    "    \"x\": \"tot\",\n",
    "    \"y\": \"tof\",\n",
    "    \"xlabel\": \"TOT (ns)\",\n",
    "    \"ylabel\": \"TOF (µs)\",\n",
    "}\n",
    "\n",
    "bins1 = (range(256), np.linspace(2.35, 2.55, 256))\n",
    "bins2 = (np.arange(0, 3000, 25), np.linspace(2.35, 2.55, 256))\n",
    "\n",
    "hv.Layout(\n",
    "    (hist2D_vmi(df1, p1, bins=bins1) + hist2D_vmi(df2, p2, bins=bins1))\n",
    "    + (hist2D_vmi(df3, p3, bins=bins2) + hist2D_vmi(df4, p4, bins=bins2))\n",
    ").cols(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_raw.query(f\"tof>2.33 & tof<2.55 & x > 100 & x < 170 & y > 100 & y < 170\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_nr, nr_pixels = np.unique(df[\"nr\"], return_counts=True)\n",
    "trigger_nr[nr_pixels.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"plotly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = df.query(\"nr==55752\")\n",
    "print(ddf.shape)\n",
    "hv.Scatter3D(ddf, kdims=[\"x\", \"y\", \"tof\"], vdims=\"tot\").opts(color=\"tot\", size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"plotly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array((len(x_bins) - 1) * [x_bins[:-1]])\n",
    "y = np.array((len(y_bins) - 1) * [y_bins[:-1]])\n",
    "heights = xy_hist.T[::-1]\n",
    "\n",
    "hv.Surface(heights, bounds=(x_bins[0], y_bins[0], x_bins[-1], y_bins[-1])).opts(\n",
    "    width=800, height=800, cmap=\"jet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# proton peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_peer_all.query(\"tof > 0.5 & tof < 1\")\n",
    "x_hist, x_bins = np.histogram(df[\"tof\"], bins=500)\n",
    "hv.Histogram((x_hist, x_bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = {\n",
    "    \"title\": f\"Protons, whole pulse train\",\n",
    "    \"x\": \"x\",\n",
    "    \"y\": \"tof\",\n",
    "    \"xlabel\": \"x (pixel)\",\n",
    "    \"ylabel\": \"TOF (µs)\",\n",
    "}\n",
    "p2 = p1.copy()\n",
    "p2[\"x\"] = \"y\"\n",
    "p2[\"xlabel\"] = \"y (pixel)\"\n",
    "df2 = data_peer_all.query(f\"tof > 0.7 & tof < 0.8\")\n",
    "bins = (range(256), np.linspace(0.7, 0.8, 256))\n",
    "\n",
    "# whole pulse train\n",
    "xy_hist, x_bins, y_bins = np.histogram2d(\n",
    "    df2[\"x\"],\n",
    "    df2[\"tof\"],\n",
    "    bins=bins,\n",
    ")\n",
    "x, y = [100, 179], [0.721, 0.725]\n",
    "a = hv.Curve((x, y), label=f\"{(y[1]-y[0])/(x[1]-x[0])*1e3*256:.1f} ns/256 pixel\")\n",
    "x, y = [100, 179], [0.721, 0.7285]\n",
    "c = hv.Curve((x, y), label=f\"{(y[1]-y[0])/(x[1]-x[0])*1e3*256:.1f} ns/256 pixel\")\n",
    "\n",
    "x, y = [82, 166], [0.727, 0.723]\n",
    "b = hv.Curve((x, y), label=f\"{(y[1]-y[0])/(x[1]-x[0])*1e3*256:.1f} ns/256 pixel\")\n",
    "hist2D_vmi(df2, p1, bins=bins, sigma=0.9) * a * c + hist2D_vmi(\n",
    "    df2, p2, bins=bins, sigma=0.9\n",
    ") * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = {\n",
    "    \"title\": f\"Protons raw, whole pulse train\",\n",
    "    \"x\": \"x\",\n",
    "    \"y\": \"tof\",\n",
    "    \"xlabel\": \"x (pixel)\",\n",
    "    \"ylabel\": \"TOF (µs)\",\n",
    "}\n",
    "p2 = p1.copy()\n",
    "p2[\"x\"] = \"y\"\n",
    "p2[\"xlabel\"] = \"y (pixel)\"\n",
    "df2 = data_raw_all.query(f\"tof > 0.7 & tof < 0.8\")\n",
    "bins = (range(256), np.linspace(0.7, 0.8, 256))\n",
    "\n",
    "# whole pulse train\n",
    "xy_hist, x_bins, y_bins = np.histogram2d(\n",
    "    df2[\"x\"],\n",
    "    df2[\"tof\"],\n",
    "    bins=bins,\n",
    ")\n",
    "x, y = [97, 180], [0.716, 0.7185]\n",
    "a = hv.Curve((x, y), label=f\"{(y[1]-y[0])/(x[1]-x[0])*1e3*256:.1f} ns/256 pixel\")\n",
    "x, y = [96, 189], [0.708, 0.71]\n",
    "c = hv.Curve((x, y), label=f\"{(y[1]-y[0])/(x[1]-x[0])*1e3*256:.1f} ns/256 pixel\")\n",
    "\n",
    "x, y = [82, 180], [0.721, 0.718]\n",
    "b = hv.Curve((x, y), label=f\"{(y[1]-y[0])/(x[1]-x[0])*1e3*256:.1f} ns/256 pixel\")\n",
    "hist2D_vmi(df2, p1, bins=bins, sigma=0.9) * a * c + hist2D_vmi(\n",
    "    df2, p2, bins=bins, sigma=0.9\n",
    ") * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electrons from Dec 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw, data_cent = get_data_pd(\"../FlashDec19/out/run_0685_20191217-1533.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_cent.query(f\"tof > 0.95 & tof < 0.97\")\n",
    "x_hist, x_bins = np.histogram(df[\"tof\"], bins=100)\n",
    "x_axe = get_x_axis_from_bins(x_bins)\n",
    "popt, cov = curve_fit(gauss_fwhm, x_axe, x_hist, p0=[1000, 1, 1])\n",
    "b = hv.Curve(\n",
    "    (x_axe, gauss_fwhm(x_axe, *popt)),\n",
    "    label=f\"FWHM {popt[2]*1e3:.1f} ns, x0={popt[1]:.3f} µs\",\n",
    ")\n",
    "\n",
    "hv.Histogram((x_hist, x_bins)).opts(xlabel=\"TOF (µs)\") * b.opts(\n",
    "    line_width=2, color=\"red\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = {\n",
    "    \"title\": f\"Electrons Dec 2019\",\n",
    "    \"x\": \"x\",\n",
    "    \"y\": \"tof\",\n",
    "    \"xlabel\": \"x (pixel)\",\n",
    "    \"ylabel\": \"TOF (µs)\",\n",
    "}\n",
    "p2 = p1.copy()\n",
    "p2[\"x\"] = \"y\"\n",
    "p2[\"xlabel\"] = \"y (pixel)\"\n",
    "df2 = data_cent.query(f\"tof > 0.94 & tof < 0.97\")\n",
    "bins = (range(256), np.linspace(0.955, 0.966, 256))\n",
    "\n",
    "# whole pulse train\n",
    "xy_hist, x_bins, y_bins = np.histogram2d(\n",
    "    df2[\"x\"],\n",
    "    df2[\"tof\"],\n",
    "    bins=bins,\n",
    ")\n",
    "\n",
    "x, y = [87, 220], [0.9565, 0.9579]\n",
    "a = hv.Curve((x, y), label=f\"{(y[1]-y[0])/(x[1]-x[0])*1e3*256:.1f} ns/256 pixel\").opts(\n",
    "    line_width=1.3, color=\"red\"\n",
    ")\n",
    "\n",
    "hist2D_vmi(df2, p1, bins=bins, sigma=1.1) * a + hist2D_vmi(\n",
    "    df2, p2, bins=bins, sigma=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = {\n",
    "    \"title\": f\"Electrons, raw Dec 2019\",\n",
    "    \"x\": \"x\",\n",
    "    \"y\": \"tof\",\n",
    "    \"xlabel\": \"x (pixel)\",\n",
    "    \"ylabel\": \"TOF (µs)\",\n",
    "}\n",
    "p2 = p1.copy()\n",
    "p2[\"x\"] = \"y\"\n",
    "p2[\"xlabel\"] = \"y (pixel)\"\n",
    "df2 = data_raw.query(f\"tof > 0.8 & tof < 1.2\")\n",
    "bins = (range(256), np.linspace(0.95, 0.985, 256))\n",
    "\n",
    "x, y = [87, 220], [0.9565, 0.9579]\n",
    "a = hv.Curve((x, y), label=f\"{(y[1]-y[0])/(x[1]-x[0])*1e3*256:.1f} ns/256 pixel\").opts(\n",
    "    line_width=1.3, color=\"red\"\n",
    ")\n",
    "hist2D_vmi(df2, p1, bins=bins, sigma=1.1) + hist2D_vmi(df2, p2, bins=bins, sigma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
